{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import itertools\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_cluster_table = pd.read_excel(\"step_data/cluster_result_combine_all_sentiments_no_dup_tag4.xlsx\")\n",
    "keywords_table = pd.read_excel(r\"model_input\\keywords\\keywords_sentimental_words.xlsx\", sheet_name='情感分析关键词')\n",
    "keywords_table_add = pd.read_excel(r\"model_input\\keywords\\keywords_sentimental_words.xlsx\", sheet_name='关键词补充')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_cluster_table['sentiment'] = origin_cluster_table['new_sentiment']\n",
    "del origin_cluster_table['new_sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_table = pd.concat([keywords_table, keywords_table_add])\n",
    "keywords_table = keywords_table.drop_duplicates(subset=['关键字', '一级'])[['关键字', '一级', '二级']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>关键字</th>\n",
       "      <th>一级</th>\n",
       "      <th>二级</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>舒服</td>\n",
       "      <td>舒适</td>\n",
       "      <td>/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>柔软</td>\n",
       "      <td>舒适</td>\n",
       "      <td>脚感软</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>缓震</td>\n",
       "      <td>性能</td>\n",
       "      <td>缓震</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>透气</td>\n",
       "      <td>舒适</td>\n",
       "      <td>透气</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>减震</td>\n",
       "      <td>性能</td>\n",
       "      <td>缓震</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  关键字  一级   二级\n",
       "0  舒服  舒适    /\n",
       "1  柔软  舒适  脚感软\n",
       "2  缓震  性能   缓震\n",
       "3  透气  舒适   透气\n",
       "4  减震  性能   缓震"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      舒\n",
       "1      柔\n",
       "2      缓\n",
       "3      透\n",
       "4      减\n",
       "      ..\n",
       "154    宽\n",
       "155    窄\n",
       "157    贴\n",
       "158    容\n",
       "159    轻\n",
       "Name: 关键字, Length: 500, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(keywords_table[\"关键字\"].str[0].unique())  # 关键词的第一个字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeywordIndex:\n",
    "    def __init__(self, table):\n",
    "        self.table = table\n",
    "        self.index = defaultdict(list)\n",
    "        for i, ch in enumerate(self.table[\"关键字\"].str[0]):\n",
    "            self.index[ch].append(i)                             # i,关键词所在的行\n",
    "        self.index_keys = set(self.index)\n",
    "    \n",
    "    def find(self, sentence):\n",
    "        result = []\n",
    "        possible_ch = set(sentence) & self.index_keys\n",
    "        possible_keywords = itertools.chain(*[self.index[ch] for ch in possible_ch]) # 可能会存在的关键词所在的行号\n",
    "        for i in possible_keywords:\n",
    "            row = self.table.iloc[i]\n",
    "            if row[\"关键字\"] in sentence:\n",
    "                result.append(row)\n",
    "        return result\n",
    "\n",
    "class KeywordFinder:\n",
    "    def __init__(self, table, sentiment_aware):\n",
    "        basic_table = self.build(table, None)\n",
    "        self.tables = {\n",
    "            \"all\": basic_table,\n",
    "            \"pos\": basic_table,\n",
    "            \"neg\": basic_table\n",
    "        }\n",
    "        if sentiment_aware:\n",
    "            self.tables[\"pos\"] = self.build(table, \"情感倾向 != '负面'\")\n",
    "            self.tables[\"neg\"] = self.build(table, \"情感倾向 != '正面'\")\n",
    "    \n",
    "    def build(self, table, query):\n",
    "        if query is not None:\n",
    "            table = table.query(query)\n",
    "        index = {}\n",
    "        for key, group in keywords_table.groupby(\"一级\"):\n",
    "            index[key] = KeywordIndex(group)\n",
    "        return index\n",
    "    \n",
    "    def find(self, sentence, spaces, sentiment=\"all\"):\n",
    "        result = []\n",
    "        table = self.tables[sentiment]\n",
    "        for space in spaces:\n",
    "            result.extend(table[space].find(sentence))\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Retagger:\n",
    "    columns = [\"sentiment\", \"cluster_id\", \"cluster_size\", \"center_sentence\", \"tag_1\", \"中心语断句\", \"关键字\"]\n",
    "    def __init__(self, keywords, topics, sentiment_aware=False):\n",
    "        self.topics = topics\n",
    "        self.keyword_finder = KeywordFinder(keywords, sentiment_aware)\n",
    "        \n",
    "    def __call__(self, df):\n",
    "        result = []\n",
    "        for _, row in df.iterrows():\n",
    "            result.extend(self.retag_row(row))\n",
    "        return pd.DataFrame(result)\n",
    "\n",
    "    def retag_row(self, row):\n",
    "        if row[\"一级\"] in [\"适用场景\", \"人群\", \"复购\", '精神认同']:\n",
    "            return []\n",
    "        if row[\"处理级别\"] <= 1:                   # 手动删除了一些尾巴的句子或者段落没有问题\n",
    "            return [row]\n",
    "        elif row[\"处理级别\"] <= 3:                 # 一级分类内部有问题\n",
    "            space = row[\"备注\"].split(\" \")\n",
    "            return self.search(row, space)\n",
    "        elif row[\"处理级别\"] == 4:\n",
    "            return self.command(row)\n",
    "        else:\n",
    "            return []\n",
    "\n",
    "    def search(self, row, space):\n",
    "        if \"positive\" in row[\"sentiment\"]:\n",
    "            sentiment = \"pos\"\n",
    "        elif \"negative\" in row[\"sentiment\"]:\n",
    "            sentiment = \"neg\"\n",
    "        else:\n",
    "            sentiment = \"all\"\n",
    "        cache = defaultdict(list)\n",
    "        for sentence in row[\"去重段落\"].split(\",\"):\n",
    "            found = self.keyword_finder.find(sentence, space, sentiment)\n",
    "            for keyword_row in found:\n",
    "                cache[(keyword_row[\"一级\"], keyword_row[\"二级\"])].append(sentence)\n",
    "        result = []\n",
    "        for (lv1, lv2), sentences in cache.items():\n",
    "            result.append(pd.concat([\n",
    "                row[self.columns],\n",
    "                pd.Series({\"一级\": lv1, \"二级\": lv2, \"去重段落\": \",\".join(sentences), \"去重段落数\": len(sentences)})\n",
    "            ]))\n",
    "        return result\n",
    "    \n",
    "    def command(self, row):\n",
    "        cmd = row[\"备注\"][:2]                     # 去除、保留、补充\n",
    "        topic = row[\"备注\"][2:]\n",
    "        topics = topic.split(\" \")\n",
    "        if cmd == \"去除\":\n",
    "            return self._do_remove(topics, row)\n",
    "        if cmd == \"保留\":\n",
    "            return self._do_filter(topics, row)\n",
    "        if cmd == \"补充\":\n",
    "            return self._do_add(topics, row)\n",
    "        raise ValueError(cmd, topic, row)\n",
    "        \n",
    "    @staticmethod\n",
    "    def _word_shows(sentence, words):\n",
    "        return any(word in sentence for word in words)\n",
    "    \n",
    "    def _do_filter(self, topic, row):   # 保留 句子中含有指定词汇则去除这个句子\n",
    "        sentences = row[\"去重段落\"].split(\",\")\n",
    "#         sentences = [sentence for sentence in sentences if self._word_shows(sentence, self.topics[topic])]\n",
    "        sentences = [sentence for sentence in sentences if self._word_shows(sentence, topic)]\n",
    "        row = row.copy()\n",
    "        row[\"去重段落\"] = \",\".join(sentences)\n",
    "        row[\"去重段落数\"] = len(sentences)\n",
    "        return [row]\n",
    "    \n",
    "    def _do_remove(self, topic, row):   # 去除 句子中含有指定词汇则去除这个句子\n",
    "        sentences = row[\"去重段落\"].split(\",\")\n",
    "        sentences = [sentence for sentence in sentences if not self._word_shows(sentence, topic)]\n",
    "        row = row.copy()\n",
    "        row[\"去重段落\"] = \",\".join(sentences)\n",
    "        row[\"去重段落数\"] = len(sentences)\n",
    "        return [row]\n",
    "    \n",
    "    def _do_add(self, topics, row):   # 补充 一级分类\n",
    "        result = self.search(row, topics)\n",
    "        result.insert(0, row)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = {\n",
    "    \"不像正品\": [\"不像正品\"],\n",
    "    \"不透气\": [\"不透气\"],\n",
    "    \"不磨脚\": [\"不磨脚\"],\n",
    "    \"有差异有差别难看\": [\"有差异有差别难看\"],\n",
    "}   # 暂时没有用到这个功能\n",
    "retagger = Retagger(keywords_table, topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_clusters = retagger(origin_cluster_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_clusters.to_excel(\"step_data/normal_cluster_cleaned.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 合并所有类的精调结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_clusters = pd.read_csv('step_data/part4_clean_special_clusters_all.csv') # 场景人群精神认同复购\n",
    "special_clusters.columns = ['一级', '二级', '去重段落数', '去重段落', '情感倾向']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_clusters1 = normal_clusters[['一级', '二级', '去重段落数', '去重段落', 'sentiment']].sort_values(by=['一级','二级']).reset_index(drop=True)\n",
    "normal_clusters1.columns = ['一级', '二级', '去重段落数', '去重段落', '情感倾向']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttl_clusters = pd.concat([special_clusters, normal_clusters1])\n",
    "ttl_clusters.to_csv(r\"model_result/语料库/corpus_final.csv\", index=False, encoding='utf-8')\n",
    "ttl_clusters.to_excel(r\"model_result/语料库/corpus_final.xlsx\", index=False, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
