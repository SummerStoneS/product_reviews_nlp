{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf973963",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_serving.client import BertClient\n",
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from Bio.Cluster import kcluster\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# from pyclustering.cluster.kmeans import kmeans, kmeans_visualizer\n",
    "# from pyclustering.cluster.center_initializer import kmeans_plusplus_initializer\n",
    "# from pyclustering.cluster.kmeans import kmeans, kmeans_visualizer\n",
    "# from pyclustering.cluster.center_initializer import kmeans_plusplus_initializer\n",
    "import time\n",
    "import random\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "204745a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_cluster(data, cluster_num=105):\n",
    "    clf = KMeans(n_clusters=cluster_num)\n",
    "    clf.fit(data)\n",
    "    centers = clf.cluster_centers_\n",
    "    labels = clf.labels_\n",
    "    return centers, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abab975f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_result_ranked_output(initial_comments, sen2vec, labels, centers=None, ascending=False):\n",
    "    \"\"\"\n",
    "        initial_comments: 原始的评论\n",
    "        sen2vec: 原始评论的feature vectors\n",
    "        labels：评论聚类后的类别\n",
    "        centers:评论聚类后的中心，如果没有后面会生成\n",
    "        ascending: True 说明按照每句话跟中心相似度由高到低排序输出\n",
    "    \n",
    "    \"\"\"\n",
    "    cluster_result_list = []\n",
    "    initial_comments_array = np.array(initial_comments)\n",
    "    for cluster_id in range(cluster_num):\n",
    "        center_sentence = None\n",
    "        cluster_sentences = initial_comments_array[labels == cluster_id]\n",
    "        cluster_vectors = sen2vec[labels == cluster_id]\n",
    "        if centers is None:\n",
    "            center_index = np.argmax(cosine_similarity(cluster_vectors).mean(axis=1)) # 用跟其他所有句子平均相似度最高的句子作为中心语\n",
    "            cluster_center = cluster_vectors[center_index]\n",
    "            center_sentence = cluster_sentences[center_index]\n",
    "        else:\n",
    "            cluster_center = centers[cluster_id]              # 类的中心\n",
    "        similarity = cosine_similarity(cluster_vectors, cluster_center.reshape(1,-1))\n",
    "        sentences_with_similarity = list(zip(np.array(cluster_sentences), similarity))\n",
    "        sentences_with_similarity.sort(key=lambda x:x[1], reverse=ascending)    # 按照离中心的相似度倒序输出段落（reverse=True）\n",
    "        if not center_sentence:\n",
    "            if ascending:\n",
    "                center_sentence = list(zip(*sentences_with_similarity))[0][0]   # 第一句是离中心意思最近的\n",
    "            else:\n",
    "                center_sentence = list(zip(*sentences_with_similarity))[0][-1]  # 最后一句是离中心意思最近的\n",
    "        cluster_result_list.append((cluster_id, len(cluster_sentences), center_sentence, \",\".join(list(zip(*sentences_with_similarity))[0])))\n",
    "    return pd.DataFrame(cluster_result_list, columns=[\"cluster_id\", \"cluster_size\", \"center_sentence\", \"cluster_sentences\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfd4f9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_result_output(initial_comments, labels, centers):\n",
    "    \"\"\"\n",
    "        initial_comments: 原始的评论，非评论用于的feature\n",
    "        labels: 评论feature聚完类的类别\n",
    "        return: dataframe of 类，类里句子个数，类里的所有句子\n",
    "    \"\"\"\n",
    "    cluster_result = []\n",
    "    cluster_df = pd.DataFrame(np.stack([initial_comments, labels]).T, columns=['sentence', 'cluster'])\n",
    "    for cluster in range(len(cluster_df['cluster'].unique())):\n",
    "        cluster_data = cluster_df[cluster_df['cluster'] == cluster]['sentence'].tolist()\n",
    "        cluster_result.append((cluster, len(cluster_data), \",\".join(cluster_data)))\n",
    "    cluster_result = pd.DataFrame(cluster_result,columns=['cluster', 'size', 'sentences'])\n",
    "    return cluster_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9a9bf46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_kmeans(sen2vec, cluster_num):\n",
    "    clusterid, error, nfound = kcluster(sen2vec, cluster_num, dist='u')\n",
    "    return clusterid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f0fb19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sentiment_sentences_file_from_step1(senti_type='positive'):\n",
    "    \"\"\"\n",
    "        senti_type: positive, negative, neutral\n",
    "        return: list of sentences\n",
    "    \"\"\"\n",
    "    print(f\"读取{senti_type}评论的情感分析\")\n",
    "    with open(f\"model_result/sentiment/{senti_type}_sentence_list.txt\", 'r', encoding='utf-8') as f:\n",
    "        senti_comments = f.read().splitlines()\n",
    "    print(\"非重复段落数: \", len(senti_comments))\n",
    "    return senti_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e9b41ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sen2vec(sentiment_type, is_first_time=True, sample_rate=1):\n",
    "    if is_first_time:\n",
    "        sentiment_comments = read_sentiment_sentences_file_from_step1(senti_type=sentiment_type)\n",
    "        sample_sentences = random.sample(sentiment_comments, round(sample_rate * len(sentiment_comments)))\n",
    "        bc = BertClient()\n",
    "        sen2vec = bc.encode(sample_sentences)\n",
    "        sentence_vec_dict = dict(zip(sample_sentences, sen2vec.tolist()))\n",
    "        with open(f\"step_data/{sentiment_type}_sample_{sample_rate}_sentence_vec_dict.json\",'w',encoding='utf-8') as f:\n",
    "            json.dump(sentence_vec_dict, f)\n",
    "    else:\n",
    "        sentence_vec_dict = json.load(open(f\"step_data/{sentiment_type}_sample_{sample_rate}_sentence_vec_dict.json\"))\n",
    "    return sentence_vec_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9921aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "读取no_keyword_positive评论的情感分析\n",
      "非重复段落数:  222864\n"
     ]
    }
   ],
   "source": [
    "# sentiment_type = 'neutral'\n",
    "sample_rate = 1\n",
    "for sentiment_type in ['positive', 'negative', 'neutral', 'no_keyword_negative', 'no_keyword_positive', 'no_keyword_neutral']:\n",
    "    sentence_vec_dict = load_sen2vec(sentiment_type, is_first_time=True, sample_rate=1)\n",
    "    sample_sentences, sen2vec = list(sentence_vec_dict.keys()), np.array(list(sentence_vec_dict.values()))\n",
    "    # 余弦距离KMEANS聚类\n",
    "    cluster_num = round(len(sample_sentences) / 1000)\n",
    "    print(\"kcluster聚类\")\n",
    "    clusterid, error, nfound = kcluster(sen2vec, cluster_num, dist='u')\n",
    "    # 按照离中心语句的距离由近到远排序输出保存\n",
    "    a = cluster_result_ranked_output(sample_sentences, sen2vec, clusterid, centers=None, ascending=True)\n",
    "    b = pd.concat([pd.Series([sentiment_type]*len(a), name='sentiment'), a], axis=1)\n",
    "    b.to_excel(f\"model_result/cluster/classify_sample_{sample_rate}_{sentiment_type}_cos_kmeans_ascending_{cluster_num}.xlsx\", index=False)\n",
    "    # 按照离中心语句的距离由远到近排序输出保存\n",
    "    a = cluster_result_ranked_output(sample_sentences, sen2vec, clusterid, centers=None, ascending=False)\n",
    "    b = pd.concat([pd.Series([sentiment_type]*len(a), name='sentiment'), a], axis=1)\n",
    "    b.to_excel(f\"model_result/cluster/classify_sample_{sample_rate}_{sentiment_type}_cos_kmeans_descending_{cluster_num}.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2f495af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed1b4be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "b.to_excel(f\"model_result/cluster/classify_sample_{sample_rate}_{sentiment_type}_cos_kmeans_ascending_{cluster_num}.xlsx\", index=False)\n",
    "# 按照离中心语句的距离由远到近排序输出保存\n",
    "a = cluster_result_ranked_output(sample_sentences, sen2vec, clusterid, centers=None, ascending=False)\n",
    "b = pd.concat([pd.Series([sentiment_type]*len(a), name='sentiment'), a], axis=1)\n",
    "b.to_excel(f\"model_result/cluster/classify_sample_{sample_rate}_{sentiment_type}_cos_kmeans_descending_{cluster_num}.xlsx\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
